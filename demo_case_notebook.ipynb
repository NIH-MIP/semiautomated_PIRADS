{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code\n",
    "# uses pre-aligned files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-239265364014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimageio\u001b[0m \u001b[1;31m#2.5.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;31m#1.3.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic_train\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic_train\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "#python imports - python version is 3.7.3\n",
    "import os\n",
    "from collections import Counter \n",
    "import numpy as np #1.17.0\n",
    "import pandas as pd #0.25.0\n",
    "import pydicom #1.3.0\n",
    "from matplotlib import pyplot as plt #matplotlib 3.1.1\n",
    "from PIL import Image #Pillow 6.1.0\n",
    "from functools import reduce\n",
    "import cv2 #opencv-python 4.1.0.25\n",
    "import sklearn #0.2.1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import imageio #2.5.0\n",
    "import scipy #1.3.0\n",
    "from fastai.basic_train import *\n",
    "from fastai.basic_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local imports \n",
    "from parsing_VOI import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first create new file called 'active_jpegs' and\n",
    "# create jpegs for all these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input path to files\n",
    "patient_path=r'C:\\Users\\sanfordt\\Desktop\\jupyter_notebook\\demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_dicom(dicom_file_list):\n",
    "    '''\n",
    "    function to sort dicom files in z space. Relys on pydicom ds.SliceLocation\n",
    "    :param dicom_file_list --> full path to dicom files to sort\n",
    "    :return list of file paths sorted from apex to base of prostate in axial plane\n",
    "    '''\n",
    "    dicoms={}\n",
    "    for path in dicom_file_list:\n",
    "        file=path\n",
    "        ds=pydicom.read_file(path)\n",
    "        dicoms[str(file)] = float(ds.SliceLocation)\n",
    "    updated_imagelist=[key for (key, value) in sorted(dicoms.items(), key=lambda x: x[1])]\n",
    "    return(updated_imagelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(path_to_image,vals,patient_dir,index,series,pad=10):\n",
    "    '''\n",
    "    helper function that takes in path to image, values and performs the segmentation\n",
    "    :param path_to_image: full path to dicom file\n",
    "    :param vals: indexes\n",
    "    :param patient_dir:\n",
    "    :param index:\n",
    "    :param series:\n",
    "    :param pad: number of voxes around the image in question\n",
    "    :return:\n",
    "    '''\n",
    "    ds = pydicom.dcmread(path_to_image)\n",
    "    data = ds.pixel_array\n",
    "    data=rescale_array(data)  #normalize by slice\n",
    "\n",
    "    print('The image has {} x {} voxels'.format(data.shape[0],data.shape[1]))\n",
    "    data_downsampled = data[vals[2] - pad:vals[4] + pad, vals[1] - pad:vals[3] + pad]\n",
    "    print('The cropped image has {} x {} voxels'.format(\n",
    "        data_downsampled.shape[0], data_downsampled.shape[1]))\n",
    "\n",
    "    ds.PixelData = data_downsampled.tobytes()\n",
    "    ds.Rows, ds.Columns = data_downsampled.shape\n",
    "\n",
    "    if not os.path.exists(os.path.join(patient_path,'T2', patient_dir)):\n",
    "        os.mkdir(os.path.join(patient_path,'T2', patient_dir))\n",
    "    os.chdir(os.path.join(patient_path,'T2',patient_dir))\n",
    "\n",
    "    #save image\n",
    "    #if series == 't2':\n",
    "    #    ds.save_as(patient_dir + '_' + str(index) + '_T2_' + vals[0] + '.dcm')\n",
    "\n",
    "    return data_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voi_paths(filetype='PIRADS'):\n",
    "    '''\n",
    "    function to find all .voi files within a specific patient directory. \n",
    "    :param filetype (str): type of segementation to perform\n",
    "           PIRADS - tumor\n",
    "           wp- whole prostate\n",
    "           u -urethra\n",
    "    :return: list of files that have the search term of interest (i.e. 'PIRADS')\n",
    "    '''\n",
    "    voi_dir=os.path.join(patient_path,'data', 'voi')\n",
    "    file_path=None\n",
    "    for file in os.listdir(voi_dir):\n",
    "        split_file=file.replace(' ','_').split('_')\n",
    "        if filetype not in split_file:\n",
    "            continue\n",
    "        elif filetype in split_file:\n",
    "            file_path=str(os.path.join(voi_dir,file))\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_paths():\n",
    "    '''\n",
    "    start in patient directory, then find all dicom files listed in that directory -->  note adc and highb\n",
    "    are aligned to t2\n",
    "    :param patient_dir (str): the folder name of the files\n",
    "    :return: list of paths to dicom files within patient directory\n",
    "    '''\n",
    "\n",
    "    #set base directory\n",
    "    pat_dir=os.path.join(patient_path,'data','dicoms')\n",
    "\n",
    "    #set path to each directory for aligned files\n",
    "    t2_dir=os.path.join(pat_dir,'t2')\n",
    "    adc_dir=os.path.join(pat_dir,'adc','aligned')\n",
    "    highb_dir=os.path.join(pat_dir,'highb','aligned')\n",
    "\n",
    "    #setup dict names\n",
    "    series_dict={'t2':t2_dir,'adc':adc_dir,'highb':highb_dir}\n",
    "\n",
    "    #loop over series and joint with series dir path to get paths to dicom files for all images in all series\n",
    "    dicom_dict={}\n",
    "    for series in series_dict.keys():\n",
    "        files=os.listdir(series_dict[series])\n",
    "        path_list=[]\n",
    "        for file in files:\n",
    "            path_list+=[os.path.join(series_dict[series],file)]\n",
    "        path_list=order_dicom(path_list)\n",
    "        dicom_dict[series]=path_list\n",
    "    return dicom_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_array(array):\n",
    "    scaler=MinMaxScaler(feature_range=(0,255))\n",
    "    scaler=scaler.fit(array)\n",
    "    X_scaled=scaler.transform(array)\n",
    "    return (X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_aligned():\n",
    "    '''\n",
    "    for files that are already aligned, this looks up dicom paths, voi paths, and segments all the images,\n",
    "    then saves the T2 and the combination of 3 separately\n",
    "    :param patient_dir --> output of completed_files\n",
    "    :return: all segmented files\n",
    "    '''\n",
    "    voi_p_paths=voi_paths()\n",
    "    for voi_path in [voi_p_paths]:\n",
    "        \n",
    "        #get name for later use\n",
    "        name=os.path.basename(os.path.normpath(voi_path))\n",
    "        dicom_path_list=dicom_paths()\n",
    "        bboxes = ParseVOI().BBox_from_position(voi_path) #from parsingVOI module\n",
    "\n",
    "        #start by iterating over bounding boxes\n",
    "        index = 0\n",
    "        for bbox in bboxes.keys():\n",
    "            vals=bboxes[bbox] #select values for each bounding box\n",
    "\n",
    "            #for each bounding box, select the appropriate slice and segment\n",
    "            segmented_image_dict={}\n",
    "            for series in dicom_path_list:\n",
    "                paths=dicom_path_list[series]\n",
    "                path_to_load=paths[int(bbox)]\n",
    "                segmented_image=segment_image(path_to_load,vals,patient_path,index,series)\n",
    "                segmented_image_dict[series]=segmented_image\n",
    "\n",
    "            #extract each sequance array and combine into numpy array\n",
    "            t2=segmented_image_dict['t2']; adc=segmented_image_dict['adc']; highb=segmented_image_dict['highb']\n",
    "            stacked_image=np.dstack((t2,adc,highb))\n",
    "\n",
    "            #normalize \n",
    "            stacked_image[:,:,0]=rescale_array(stacked_image[:,:,0])\n",
    "            stacked_image[:, :, 1] = rescale_array(stacked_image[:, :, 1])\n",
    "            stacked_image[:, :, 2] = rescale_array(stacked_image[:, :, 2])\n",
    "\n",
    "            #make a directory if one doesn't already exist for images, conver to Image and save .jpg\n",
    "            if not os.path.exists(os.path.join(patient_path,'data','jpg',name)):\n",
    "                os.mkdir(os.path.join(patient_path,'data','jpg',name))\n",
    "            os.chdir(os.path.join(patient_path,'data','jpg',name))\n",
    "\n",
    "            #opencv solution\n",
    "            cv2.imwrite(os.path.join(patient_path,'data','jpg',name, str(name) +'_'+str(index) + '_' + vals[0] + '.jpg'),stacked_image)\n",
    "\n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image has 384 x 384 voxels\n",
      "The cropped image has 48 x 37 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 48 x 37 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 48 x 37 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 46 x 33 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 46 x 33 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 46 x 33 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 42 x 40 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 42 x 40 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 42 x 40 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 46 x 38 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 46 x 38 voxels\n",
      "The image has 384 x 384 voxels\n",
      "The cropped image has 46 x 38 voxels\n"
     ]
    }
   ],
   "source": [
    "segment_aligned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model():        \n",
    "    #import model\n",
    "    model_path = os.path.join(patient_path,'model')\n",
    "    learn = load_learner(model_path)\n",
    "    \n",
    "    for tumor in os.listdir(os.path.join(test_path)):\n",
    "        print(tumor)\n",
    "        sum_pred = np.zeros(4)\n",
    "        square_pred = np.zeros(4)\n",
    "        img_num = 0\n",
    "\n",
    "        for image in sorted(os.listdir(os.path.join(test_path, tumor))):\n",
    "            img = open_image(os.path.join(test_path, tumor, image))\n",
    "            pred_class, pred_idx, outputs = learn.predict(img)\n",
    "            print(outputs.numpy())\n",
    "            sum_pred += outputs.numpy()\n",
    "            square_pred += (outputs.numpy()) ** 2\n",
    "            img_num += 1\n",
    "        \n",
    "        # metrics\n",
    "        average = sum_pred / img_num\n",
    "        sum_pred_class = np.argmax(sum_pred)\n",
    "        ave_pred_class = np.argmax(average)\n",
    "        square_pred_class = np.argmax(square_pred)\n",
    "\n",
    "        print('sum prediction {}'.format(sum_pred))\n",
    "        print('average prediction {}'.format(average))\n",
    "        print('square prediction {}'.format(square_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_learner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c76b9070750d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mapply_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-d4aa4a3d9b32>\u001b[0m in \u001b[0;36mapply_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#import model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatient_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mlearn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_learner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtumor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_learner' is not defined"
     ]
    }
   ],
   "source": [
    "apply_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
